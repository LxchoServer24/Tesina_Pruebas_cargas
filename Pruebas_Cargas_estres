from os import listdir, getcwd, mkdir
from os.path import isfile, join
from datetime import date
import requests
import concurrent.futures
import threading
import time
import re

thread_local = threading.local()

"""interface and data"""
def getpath(name):
    path = join(getcwd(),name)
    try:
        mkdir(path)
    except OSError as error:
        """do something"""
    return path

def ls(ruta = '.'):
    return [arch for arch in listdir(ruta) if isfile(join(ruta, arch))]

def guardar(sites):
    path = getpath("data")
    name = input("guardar como: ")
    name = re.sub('[\/:*?"<>|]','', name)
    with open(path+"\\"+name+'.txt', 'w') as file:
        for item in sites:
            file.write(item+"\n")
            
def obtener(name):
    with open(name,"r") as file:
        for linea in file:
            linea = linea[:-1]
            sites.append(linea)
    return sites
            
def newlist():
    ext = True
    while ext:
        new = input("Ingrese url: ")
        sites.append(new)
        a =  input("agregar otro url, s / n  > ")
        while a!="s" and a!="n":
            a =  input("agregar otro url, s / n  > ")
        if a == 'n':
             ext = False
    print(sites)
    a = input("desea guardar estos registros? s / n  > ")
    while a!="s" and a!="n":
        a = input("desea guardar estos registros? s / n  > ")
    if a == "s":
        guardar(sites)
    return sites
            
def readlist():
    print(ls(join(getcwd(),"data")))
    a = input("ingrese el archivo a leer")
    path = join(getcwd(),"data",a)
    sites = obtener(path)
    print(sites)
    
    return sites
    
def menu():
    a= input( "c: crear una nueva lista de URL, l: leer una lista anterior ")
    while a!="c" and a!="l":
        a = input("c: crear una nueva lista de URL, l: leer una lista anterior ")
    if a == "c":
        sites = newlist()
    else:
        sites = readlist()
    return sites
"""end interface and data"""
"""Crauling"""
def get_session():
    if not hasattr(thread_local, "session"):
        thread_local.session = requests.Session()
    return thread_local.session

def download_site(url):
    session = get_session()
    print(f"downloading {url} ")
    path = getpath("reportes")
    tdate = date.today()
    today = tdate.strftime("%d-%m-%Y")
    u = url[7:]
    name = u+ today
    name = re.sub('[\/:*?"<>|]','', name)
    with open(path+"\\"+name+'.txt','a') as file:
        with session.get(url,verify=False) as response:
            s = str(len(response.content))
            s2 = str(response.status_code)
            status = "read " + s+ " from "+url+" status_code "+ s2
            print(status)
            file.write(status+"\n")

def download_all_sites(sites):
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        executor.map(download_site, sites)
"""end crauling"""
if __name__=="__main__":
    sites = []
    path = getpath("data")
    print(ls(path))
    if(len(ls(path) ) == 0):
        sites = newlist()
    else:
        sites = menu()
    x = True
    while x:
        a = input('ingrese el numero de peticiones a hacer > ')
        if a.isdigit():
            x = False
    a = int(a)
    sites = sites*a
    stime= time.time()
    download_all_sites(sites)
    duration = time.time()-stime
    print (duration)
